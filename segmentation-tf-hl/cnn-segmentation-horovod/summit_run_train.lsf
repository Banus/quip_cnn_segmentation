#!/bin/bash
# Begin LSF Directives
#BSUB -P CSC143
#BSUB -W 1:00
#BSUB -nnodes 2
#BSUB -alloc_flags gpumps
#BSUB -alloc_flags NVME
#BSUB -J cnn-segmentation
#BSUB -o cnn-segmentation.%J
#BSUB -e cnn-segmentation.%J

set -x

module unload darshan-runtime

. /ccs/home/lot/summit/tensorflow-1.12-p3/source_to_run_tensorflow1.12-p3
PYTHON=python

BBDIR=/mnt/bb/$USER
DATADIR=${BBDIR}/data
jsrun -n 2 -r 1 -a 1 -g 0 mkdir -p ${DATADIR}
 
BASEDIR=${PROJWORK}/csc143/lot/u24 
CONTAINER=${BASEDIR}/tf-hvd-summit.simg

date
#cd ${DATADIR}
jsrun -n 2 -r 1 -a 1 -g 0 tar -xvzf ${BASEDIR}/data/original.tgz -C ${DATADIR} #One tar per node
date

cd ${BASEDIR}/quip_cnn_segmentation/segmentation-tf-hl/cnn-segmentation-horovod

MAIN=${BASEDIR}/quip_cnn_segmentation/segmentation-tf-hl/cnn-segmentation-horovod/main.py

# This one works, but only uses 1 of the three GPUs per resource set 
#jsrun -n 4 -r 2 -a 1 -g 3 -c 21 $PYTHON $MAIN

# Causes errors like: 
#   tensorflow.python.framework.errors_impl.InvalidArgumentError: 'visible_device_list' listed an invalid GPU id '3' but visible device count is 3
#jsrun -n 4 -r 2 -a 3 -g 3 -c 21 $PYTHON $MAIN


jsrun -n 12 -r 6 -a 1 -g 1 -c 7 $PYTHON $MAIN

# n -> total number of resource sets
# r -> resource sets per node
# a -> tasks 
# g -> gpus
# c -> cores


#HOROVOD_TIMELINE=horovod_trace.json time mpirun -np 4 -x HOROVOD_TIMELINE -hostfile hostfile --bind-to none --map-by slot -mca pml ob1 -mca btl ^openib singularity exec $CONTAINER python main.py &> log.train.txt &

exit 0

